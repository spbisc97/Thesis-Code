{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt \n",
    "# %matplotlib inline\n",
    "# os.environ[\"SDL_VIDEODRIVER\"] = \"dummy\"\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ffmpegio\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import A2C\n",
    "Algo=A2C\n",
    "Algo.name = \"A2C\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\n",
    "    \"LunarLander-v2\",\n",
    "    continuous  = False,\n",
    "    gravity = -10.0,\n",
    "    enable_wind = False,\n",
    "    wind_power = 15.0,\n",
    "    turbulence_power = 1.5,\n",
    "    render_mode='rgb_array')\n",
    "\n",
    "observation, info = env.reset(seed=42)\n",
    "env_name=\"LunarLander-v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dir=f\"models/{env_name}/{Algo.name}\"\n",
    "logdir = f\"logs/{env_name}/{Algo.name}\"\n",
    "imgs_dir = f\"imgs/{env_name}/{Algo.name}\"\n",
    "\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "os.makedirs(logdir, exist_ok=True)\n",
    "os.makedirs(imgs_dir, exist_ok=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print Agent Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation Space:  Box([-90.        -90.         -5.         -5.         -3.1415927  -5.\n",
      "  -0.         -0.       ], [90.        90.         5.         5.         3.1415927  5.\n",
      "  1.         1.       ], (8,), float32)\n",
      "Sample Observation [36.16341    -6.052117    3.8429792   1.1116247  -3.0068586  -2.9883487\n",
      "  0.8316981   0.89760166]\n"
     ]
    }
   ],
   "source": [
    "print(\"Observation Space: \", format(env.observation_space))\n",
    "print(\"Sample Observation\", format(env.observation_space.sample()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action Space        Discrete(4)\n",
      "Action Space Sample  3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Action Space       \", format(env.action_space))\n",
    "print(\"Action Space Sample \", format(env.action_space.sample()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Algo(\"MlpPolicy\", env, verbose=0, tensorboard_log=logdir)\n",
    "vec_env = model.get_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation Space:  Box([-90.        -90.         -5.         -5.         -3.1415927  -5.\n",
      "  -0.         -0.       ], [90.        90.         5.         5.         3.1415927  5.\n",
      "  1.         1.       ], (8,), float32)\n",
      "Sample Observation [ 8.0035486e+00 -8.5507858e+01 -5.6614917e-02 -1.4018070e+00\n",
      "  3.0723724e+00 -7.4252683e-01  8.5598242e-01  2.8504422e-01]\n"
     ]
    }
   ],
   "source": [
    "print(\"Observation Space: \", format(vec_env.observation_space))\n",
    "print(\"Sample Observation\", format(vec_env.observation_space.sample()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action Space        Discrete(4)\n",
      "Action Space Sample  2\n"
     ]
    }
   ],
   "source": [
    "print(\"Action Space       \", format(vec_env.action_space))\n",
    "print(\"Action Space Sample \", format(vec_env.action_space.sample()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_run = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = 40_000\n",
    "for i in range(last_run ,last_run + 5):\n",
    "    model.learn(total_timesteps=timesteps,reset_num_timesteps=False,tb_log_name=\"run_\"+str(format(i,'04d')))\n",
    "    model.save(f\"{models_dir}/{Algo.name}_{format(i,'04d')}\")\n",
    "    choosen_model_name=f\"{Algo.name}_{format(i,'04d')}\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Whats Learned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of steps you run the agent for \n",
    "num_episodes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can now remake the env with human mode so we can render it\n",
    "env = gym.make(\n",
    "    \"LunarLander-v2\",\n",
    "    continuous  = False,\n",
    "    gravity = -10.0,\n",
    "    enable_wind = False,\n",
    "    wind_power = 15.0,\n",
    "    turbulence_power = 1.5,\n",
    "    render_mode='rgb_array')\n",
    "# we could also change some parameters of the environment to check robustness of the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can now use the one of the models that we have saved to run the agent\n",
    "choosen_model = Algo.load(f\"{models_dir}/{choosen_model_name}\",env=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ep in range(num_episodes):\n",
    "    obs,info=env.reset()\n",
    "    term=False\n",
    "    frames=[]\n",
    "    while not term or trunc:\n",
    "        action, _state = choosen_model.predict(obs, deterministic=True)\n",
    "        obs, reward, term,trunc, info = env.step(action)\n",
    "        if ep==num_episodes-1:\n",
    "            frames+=[env.render()]\n",
    "        if term or trunc:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls><source src=./imgs/LunarLander-v2/A2C/A2C_0005.mp4 type=\"video/mp4\"></video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = f\"./{imgs_dir}/{choosen_model_name}.mp4\"\n",
    "ffmpegio.video.write(filename, 30, np.array(frames),overwrite=True,show_log=True)\n",
    "display.HTML(f\"\"\"<video alt=\"test\" controls><source src=\"\"\"+filename+\"\"\" type=\"video/mp4\"></video>\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
